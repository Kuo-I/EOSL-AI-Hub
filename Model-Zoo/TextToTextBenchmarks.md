## MediaTek Genio Series
  
  | Model            |  Chipsets  |    Framework          |    Speed (token/s)<br><sub>Prompt/Eval |   Memory (GB) |  Power (Watt) |     Temp (°C)    |
  |------------------|------------|-----------------------|--------------------|---------------|---------------|------------------|
  | deepseek-r1:1.5b |  Genio-510 | Ollama(`Cortex-A78`)   |   9.76/ 5.86      | 4GB (100%)    |               |                  |
  | llama3.2:1b      |  Genio-510 | Ollama(`Cortex-A78`)   |   21.06/ 6.44     | 4GB (100%)    |               |                  |

## AMD Ryzen AI 300 Series

基於 AMD 官方建議，本報告採用 **Ollama** 推論框架在本地執行大型語言模型，原因是其對APU提供完善的支援，能在 Windows 與 Linux 環境下直接利用 iGPU 做加速，兼顧效能、效率與本地資料隱私。

### Ryzen AI 9 HX

*  **量化等級及策略評估**<br>
  `VGM（VRAM iGPU Memory）` 是 AMD 專為 Ryzen AI 設計的記憶體最佳化技術，能在推論過程中更高效率地載入與處理模型權重及中間資料，減少 CPU 與 GPU 間的資料傳輸延遲，提升整體的推論速度與穩定性。您可以透過表格中的 CPU%、iGPU%、TTFT（Time-to-first-Token）與生成速度觀察VGM 在不同量化設定下的效能差異與運算資源分配情形。其中，量化等級以 `qX` 表示，X 為位元數(數值越低壓縮率越高，但模型精度可能會下降)；命名中的`0`、`1`、`K_Small`、`K_Medium`、`K_Large` 則代表同位元下的不同量化變體，允許使用者在速度、資源與精度之間取不同平衡。

  | Model                         |  CPU (%) | iGPU (%) |  TTFT (ms) |  Speed (token/s)  |
  |-------------------------------|----------|----------|---------------|------------|
  | qwen2.5:0.5b                  |    34    |    7     |        59.3   | 110.83     |
  | qwen2.5:0.5b-base-q2_K        |    33    |   10     |        17.6   | 108.76     |
  | qwen2.5:0.5b-base-q3_K_S      |    37    |   12     |        21.0   | 104.98     |
  | qwen2.5:0.5b-base-q3_K_M      |    45    |   11     |         20.6  | 102.63     |  
  | qwen2.5:0.5b-base-q3_K_L      |    38    |   12     |        20.5   | 105.15     |
  | qwen2.5:0.5b-base-q4_0        |    32    |   15     |        21.6   |  99.54     |
  | qwen2.5:0.5b-base-q4_1        |    33    |   10     |        26.0   |  99.45     |
  | qwen2.5:0.5b-base-q4_K_S      |    30    |    7     |         18.8  | 112.33     |
  | qwen2.5:0.5b-base-q4_K_M      |    38    |   13     |        19.0   |  96.10     |
  | qwen2.5:0.5b-base-q5_0        |    36    |   17     |        23.1   |  94.37     |
  | qwen2.5:0.5b-base-q5_1        |    35    |   11     |        27.5   |  86.98     |
  | qwen2.5:0.5b-base-q5_K_S      |    37    |   10     |        18.7   |  99.28     |
  | qwen2.5:0.5b-base-q8_0        |    36    |   12     |        14.7   |  87.27     |
    
### (不同模型的效果評估)

  | Model                        |  Chipsets  |  Framework  |  CPU (%) | GPU (%) | NPU (%) |  TTFT (ms) |  Speed (token/s)  |
  |------------------------------|------------|-------------|----------|---------|---------|---------------|------------|
  | qwen2.5:0.5b-instruct-q2_K    |    45    |   11     |        32.8   | 109.99     |
  | qwen2.5:0.5b-instruct-q3_K_M  |    38    |   16     |        35.6   | 100.94     |
  | qwen2.5:1.5b-instruct-q4_0    |    28    |   11     |       113.3   |  42.20     |  
  | qwen2.5:1.5b-instruct-q4_1    |    35    |   10     |       406.3   |  38.55     |
  | qwen2.5:1.5b-instruct-q4_K_M  |    36    |    9     |       276.5   |  44.65     |
  | qwen2.5:1.5b-instruct-q5_0    |    40    |    7     |       116.2   |  42.13     |
  | qwen2.5:1.5b-instruct-q5_K_M  |    37    |    8     |       311.8   |  42.96     |
  | qwen2.5:1.5b-instruct-q8_0    |    36    |    6     |       228.7   |  32.71     |
  | qwen2.5:1.5b-instruct-fp16    |    30    |    9     |       195.0   |  18.68     |
  | qwen2.5:3b-instruct-q3_K_M    |    31    |    8     |       317.4   |  25.49     |
  | qwen2.5:3b-instruct-q4_0      |    30    |    7     |       1.0     |  21.38     |
  | qwen2.5:3b-instruct-q4_K_M    |    33    |   11     |       550.6   |  25.48     |
  | qwen2.5:3b-instruct-q5_0      |    30    |   10     |       492.8   |  19.35     |
  | qwen2.5:3b-instruct-q5_K_M    |    37    |   11     |       341.4   |  22.10     |
  | qwen2.5:3b-instruct-q8_0      |    36    |   10     |       428.6   |  16.71     |
  |   |        |        |                 |     |
  |   |        |        |                 |     |
  |   |        |        |                 |     |
  |   |        |        |                 |     |
  |   |        |        |                 |      |
  |   |        |        |                 |      |
  |   |        |        |                 |      |

