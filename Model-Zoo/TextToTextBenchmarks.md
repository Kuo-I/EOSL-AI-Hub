## AMD Ryzen AI 300 Series

基於 AMD 官方建議，本報告採用 [**Ollama**](https://ollama.com/) 推論框架及[**LLM-Benchmark**](https://llm.aidatatools.com/)在本地測試大型語言模型，原因是其對APU提供完善的支援，能在 Windows 與 Linux 環境下直接利用 iGPU 做加速，兼顧效能、效率與本地資料隱私。

> 請注意，執行過程需透過BIOS或Adrenalin Editor開啟`VGM（VRAM iGPU Memory）`。 VGM是 AMD 專為 Ryzen AI 設計的記憶體最佳化技術，能讓推論過程更高效率地載入與處理權重及資料，減少 CPU 與 GPU 間的傳輸瓶頸與延遲，提升整體的推論速度與穩定性。

### Ryzen AI 9 HX

---

#### 量化等級及策略評估

您可以透過表格中的 **CPU%、iGPU%、TTFT（Time-to-first-Token）**與**生成速度**觀察VGM 在不同量化設定下的效能差異與運算資源分配情形。其中，量化等級以 `qX` 表示，X 為位元數(數值越低壓縮率越高，但模型精度可能會下降)；命名中的`0`、`1`、`K_Small`、`K_Medium`、`K_Large` 則代表同位元下的不同量化變體，允許使用者在速度、資源與精度之間取不同平衡。

  | Model                         |  CPU (%) | iGPU (%) |  TTFT (ms) |  Speed (token/s)  |
  |-------------------------------|----------|----------|---------------|------------|
  | qwen2.5:0.5b                  |    34    |    7     |        59.3   | 110.83     |
  | qwen2.5:0.5b-base-q2_K        |    33    |   10     |        17.6   | 108.76     |
  | qwen2.5:0.5b-base-q3_K_S      |    37    |   12     |        21.0   | 104.98     |
  | qwen2.5:0.5b-base-q3_K_M      |    45    |   11     |         20.6  | 102.63     |  
  | qwen2.5:0.5b-base-q3_K_L      |    38    |   12     |        20.5   | 105.15     |
  | qwen2.5:0.5b-base-q4_0        |    32    |   15     |        21.6   |  99.54     |
  | qwen2.5:0.5b-base-q4_1        |    33    |   10     |        26.0   |  99.45     |
  | qwen2.5:0.5b-base-q4_K_S      |    30    |    7     |         18.8  | 112.33     |
  | qwen2.5:0.5b-base-q4_K_M      |    38    |   13     |        19.0   |  96.10     |
  | qwen2.5:0.5b-base-q5_0        |    36    |   17     |        23.1   |  94.37     |
  | qwen2.5:0.5b-base-q5_1        |    35    |   11     |        27.5   |  86.98     |
  | qwen2.5:0.5b-base-q5_K_S      |    37    |   10     |        18.7   |  99.28     |
  | qwen2.5:0.5b-base-q8_0        |    36    |   12     |        14.7   |  87.27     |

---

### 模型選項及架構相容性測試

