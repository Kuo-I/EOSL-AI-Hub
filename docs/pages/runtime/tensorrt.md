---
layout: default
title: "　-　TensorRT"
nav_order: 34
---

# Install TensorRT for Jetson Boards
TensorRT is a high-performance deep learning inference engine from NVIDIA designed for NVIDIA GPUs. It supports leading deep learning frameworks such as TensorFlow, PyTorch, and ONNX, and provides a rich set of APIs and tools that allow developers to optimise and accelerate the model inference process.TensorRT supports INT8 quantisation, which significantly improves inference performance while reducing power consumption. This makes TensorRT an ideal choice for HPC and deep learning inference, and it is widely used in various HPC scenarios.
